---
title: "Projet de Séries Temporelles"
author: "Kim Antunez et Alain Quartier-la-Tente"
date: "19/05/2020"
automaticcontents: true
output:
  bookdown::pdf_document2:
        toc: true
        toc_depth: 3
        number_sections: true
        fig_width: 7
        fig_height: 6
        fig_caption: true
        highlight: default
        keep_tex: yes
urlcolor: blue
themeoptions: "coding=utf8,language=french"
classoption: 'french'
documentclass: "article"
geometry: margin=0.95in
header-includes:
- \usepackage[french]{babel}
- \usepackage{fontawesome5}
- \usepackage{multicol}
- \DeclareMathOperator{\Cov}{Cov}
- \usepackage{mathtools}
- \usepackage{caption}
- \usepackage{xspace}
- \usepackage{textpos}
before_body-includes:
- \clearpage
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
  collapse = TRUE,
  fig.path = "img/rmd-",
  fig.align = "center",
  fig.width = 8, fig.height = 3,
  warning = FALSE,
  message = FALSE)
options(knitr.kable.NA = ' ')
source("fonctions_rapport.R",encoding = "UTF-8")
```

\begin{textblock*}{\textwidth}(0cm,-14.cm)
\begin{center}
\includegraphics[height=2cm]{img/LOGO-ENSAE-avatar.png}
\end{center}
\end{textblock*}

<!-- Pour faire en sorte que la première page ne soit pas numérotée : -->
\thispagestyle{empty}
\newpage\setcounter{page}{1}

# Partie 1 : Les données

## Question 1 : description de la série choisie

Pour ce projet, travaillons sur la série d'indice de production industrielle (IPI) dans l'industrie automobile (identifiant : [010537940](https://bdm.insee.fr/series/sdmx/data/SERIES_BDM/010537940)). 
Il s'agit d'une série au niveau A64 de la nomenclature d'activités française révision 2 (NAF rév. 2, division 29), poste CL1.
L'industrie automobile concerne aussi bien la production des constructeurs de voitures particulières, de véhicules de loisir, de véhicules utilitaires que les équipementiers spécialisés, les carrossiers, les assembleurs ou les prestataires de services d’aménagement de véhicules automobiles. 
Cette production intègre donc la filière complète, y compris moteurs et organes mécaniques en amont, dès lors qu’ils sont principalement destinés à des véhicules automobiles (à l’exception des parties de moteur).

Il s'agit d'un indice de Laspeyres^[Les indices de Laspeyres et de Paasche permettent de synthétiser en un indice unique un certain nombre d'indices. L'indice de Laspeyres, le plus célèbre est l'IPC (indice des prix à la consommation).], en base 2015, chaîné avec des pondérations annuelles (les pondérations correspondant aux valeurs ajoutées des branches associées). 
L'IPI dans l'industrie automobile est calculé à partir de l'enquête mensuelle de branche, par agrégation de séries "élémentaires" estimées en volume^[La série d'IPI dans l'industrie automobile ne tient donc pas compte des variations de prix.], calculées à un niveau plus fin. 

Les séries de l'IPI sont corrigées des variations saisonnières et des jours ouvrables (CVS-CJO) à partir de la méthode X13-ARIMA. 
La désaisonnalisation est réalisée de manière indirecte : elle est effectuée à un niveau fin et les agrégats CVS-CJO sont ensuite calculés directement à partir de ces séries en agrégeant les séries CVS-CJO. 
Cette désaisonnalisation est réalisée par sous-périodes pour prendre en compte le fait que la structure économique des séries a beaucoup évolué en 30 ans, et donc qu'il serait peut pertinent d'appliquer un seul modèle de désaisonnalisation sur l'ensemble de la période. 
Ainsi, les modèles utilisés pour la désaisonnalisation commencent en 2005 et ces modèles sont utilisées pour estimer les séries CVS-CJO à partir de 2012.

Les séries CVS-CJO avant et après 2012 n'étant pas évaluées sur les mêmes modèles, l'idéal serait d'étudier notre série après janvier 2012 pour éviter des ruptures liées à ce changement de modèle. En revanche, cela laisserait une faible profondeur temporelle risquant de fragiliser l'estimation de nos modèles ARIMA. 
C'est pourquoi nous allons étudier la série d'IPI dans l'industrie automobile entre **janvier 2010 et décembre 2019**^[Lorsque nous avons commencé ce projet, l'IPI était disponible jusqu'en février 2020. 
En revanche, les derniers points étant souvent sujets à révisions, nous avons préféré ne pas prendre en compte les points de janvier et février 2020.], c'est-à-dire sur **120 observations**.

Nous n'effectuons pas ici de correction de point atypique ou de transformation logarithmique.

## Questions 2 et 3 : transformation de la série

```{r ipiBrut, fig.cap= "IPI dans l'automobile (CVS-CJO sans traitement).", include=FALSE}
data <- readRDS(file = "../data/donnees.RDS")
data_complet <- readRDS(file = "../data/donnees_completes.RDS")
models_evalues <- readRDS(file = "../data/models_evalues.RDS")
x <- data[,"ipi_cl1"]
x_st <- readRDS(file = "../data/x_st.RDS")
x_complet <- data_complet[, "ipi_cl1"]

p1 <- AQLTools::graph_ts(window(x,
								start = c(2009,10),
								end = c(2020,2),
								extend = TRUE), x_lab = "Dates", y_lab = NULL, n_xlabel = 12)
p1
```

```{r compGraph, fig.cap= "IPI dans l'automobile (CVS-CJO) sans et avec différentiation."}
p1 <- AQLTools::graph_ts(window(x,
								start = c(2009,10),
								end = c(2020,2),
								extend = TRUE), 
								x_lab = "Dates", y_lab = NULL, n_xlabel = 6,
								titre = "(a) Sans différentiation")
p2 <- AQLTools::graph_ts(window(x_st,
								start = c(2009,10),
								end = c(2020,2),
								extend = TRUE), x_lab = "Dates", y_lab = NULL, n_xlabel = 6,
								titre = "(b) Avec différentiation")
p1 + p2 
```

Le graphique \@ref(fig:compGraph)-(a) ne montre pas de tendance linéaire déterministe nette sur la période 2010-2020 : on observe plutôt une alternance entre des périodes à tendance croissante (2010-2011, 2013-2018) et à tendance décroissante (2011-2013 et 2018-2020). 
La série de l'IPI dans l'automobile semble plutôt montrer une tendance stochastique : elle n'est sûrement **pas stationnaire**. Ceci est vérifié en faisant le test Dickey-Fuller augmenté (ADF) avec une constante non nulle et sans tendance : on ne rejette pas l'hypothèse de présence de racine unitaire au seuil de 5 \% (tableau \@ref(tab:tabTestsInit)). 
Ceci est également confirmé par le test de racine unitaire de Phillips-Perron, non rejeté au seuil de 5 \%, et par le test de stationnarité^[Ici, l'hypothèse alternative est la non-stationnarité de la série] de Kwiatkowski-Phillips-Schmidt-Shin (KPSS), rejeté au seuil de 5 \%. Nous **différencions** donc la série. 



```{r tabTestsInit}
adf <- adfTest(x, type = "c",lags = 2)
pp <- PP.test(x) 
kpss <- tseries::kpss.test(x)
t1 <- test_stationnarite(adf, pp, kpss,
                   titre = "Tests de racine unitaire et de stationnarité sur la série d'IPI dans l'automobile.")
t1
```


D'après le graphique \@ref(fig:compGraph)-(b), la série différenciée semble **stationnaire**. 
Cette hypothèse est confirmée par le test de Dickey-Fuller augmenté, effectué avec une constante nulle et sans tendance, le test de Phillips-Perron et le test KPSS (tableau \@ref(tab:tabTestsDiff)).




```{r tabTestsDiff}
adf <- adfTest(x_st, type = "c",lags = 1)
pp <- PP.test(x_st) 
kpss <- tseries::kpss.test(x_st)
t2 <- test_stationnarite(adf, pp, kpss,
                   titre = "Tests de racine unitaire et de stationnarité sur la série différenciée d'IPI dans l'automobile.")
t2
```


# Partie 2 : Modèles ARIMA

Afin de déterminer les ordres maximaux, $p_{max}$ et $q_{max}$, du modèle $ARMA(p,q)$ suivi par la série différenciée de l'IPI dans l'automobile, nous analysons les autocorrélogrammes et les autocorrélogrammes partiels (graphique \@ref(fig:acfPacf)). 
À partir de retard 2 (inclus), aucun autocorrélogramme est significatif à 5 \% : on en déduit que $p_{max} = 1$.
À partir de retard 2 (inclus), aucun autocorrélogramme partiel est significatif à 5 \%: on en déduit que $q_{max} = 1$.  
Ainsi, pour savoir quel(s) modèle(s) retenir, nous allons tester tous les modèles $ARMA(p,q)$ tels que $p\leq 1$ et $q\leq 1$.

```{r acfPacf, fig.cap="Autocorrélogrammes (ACF) et autocorrélogrammes partiels (PACF) pour la série différenciée de l'IPI dans l'automobile.", fig.height=2}
reformat_graph_acf(ggAcf(x_st)) +
	reformat_graph_acf(ggPacf(x_st))
```


Quatre modèles ARMA ont donc été testés^[Ils ont été estimés sans constante.] afin de s'assurer de l'indépendance des résidus (tableau \@ref(tab:tablbtest)) et, si c'est bien le cas, de la significativité des coefficients associés aux ordres maximaux des parties AR et MA des modèles (tableau \@ref(tab:tabcoefs))  :

\begin{itemize}
\item \emph{ARMA(0,0)} : les résidus de ce modèle ne sont pas indépendants \faArrowCircleRight{} \textbf{modèle non retenu}

\item \emph{ARMA(1,0)} : les résidus de ce modèle ne sont pas indépendants \faArrowCircleRight{} \textbf{modèle non retenu}

\item \emph{ARMA(0,1)} : les résidus de ce modèle sont indépendants et le coefficient associé au MA(1) est significatif \faArrowCircleRight{} \textbf{modèle retenu}

\item \emph{ARMA(1,1)} : les résidus de ce modèle sont indépendants (tableau mais le coefficient associé au AR(1) n'est significatif \faArrowCircleRight{} \textbf{modèle non retenu}
\end{itemize}

Finalement, seul le modèle ARMA(0,1) est valide sur la série différenciée. Sur la série non différenciée de l'IPI automobile, on retient donc le modèle **ARIMA(0,1,1)** défini mathématiquement par :  

$$
\Delta X_t = \varepsilon_t - \underset{(0,09)}{0,38}\;\varepsilon_{t-1}
$$
$\varepsilon_t$ est bien un bruit blanc : les $(\varepsilon_t)_t$ sont indépendants (tableau \@ref(tab:tablbtest)), homoscédastiques (tableau \@ref(tab:tablb2test)) et suivent aussi une loi normale (tableau \@ref(tab:tabjb)).

Parmi l'ensemble des modèles testés, l'ARIMA(0,1,1) est aussi le modèle qui minimise les critères d'information (tableau \@ref(tab:aicbic)).

```{r aicbic}
format_ic(models_evalues, 
            titre = "Critères d'information des modèles ARIMA sur l'IPI de l'automobile.")
```


# Partie 3 : Prévisions

## Question 6, 7 et 8 : construction d'un intervalle de confiance

On cherche désormais à faire une prévision de $X_t$ à l'horizon $T+2$. 
Notons $\theta_1$ le coefficient associé à la partie MA de notre modèle ARMA(0,1,1), qu'on estime par $\widehat\theta_1\simeq -0,38$  (tableau \@ref(tab:tabcoefs)) en estimant le modèle entre janvier 2010 et décembre 2019. On a donc :
$$
\Delta X_T = \varepsilon_T + \theta_1\varepsilon_{T-1}
\iff 
X_T = X_{T-1} + \varepsilon_T + \theta_1\varepsilon_{T-1}
\quad\text{où}\quad
\varepsilon_t\overset{i.i.d}\sim\mathcal N(0,\sigma^2)
$$

En considérant $\theta_1$ connu, les prévisions de $X_{T+1}$ et $X_{T+2}$ réalisées à l'instant $T$, notées $\widehat X_{T+1\vert T}$ et $\widehat X_{T+2\vert T}$, vérifient l'équation :
$$
\begin{cases}
\widehat X_{T+1\vert T}= X_T + \theta_1\varepsilon_T \\
\widehat X_{T+2\vert T}=\widehat X_{T+1\vert T} =  X_T + \theta_1\varepsilon_T 
\end{cases}
$$
Les erreurs de prévision sont égales à :
$$
\begin{cases}
\widehat \varepsilon_{T+1\vert T} = X_{T+1} - \widehat X_{T+1\vert T}=
\varepsilon_{T+1}+(\theta_1-\theta_1)\varepsilon_T 
&= \varepsilon_{T+1}
\\
\widehat \varepsilon_{T+2\vert T} = X_{T+2} - \widehat X_{T+2\vert T}=
\varepsilon_{T+2}+(1+\theta_1)\varepsilon_{T+1}+(\theta_1-\theta_1)\varepsilon_T 
&=
\varepsilon_{T+2}+(1+\theta_1)\varepsilon_{T+1}
\end{cases}
$$
Les $\varepsilon_t$ étant i.i.d., $\widehat \varepsilon_{T+h\vert T} \overset{(H_0)}{\sim}\mathcal N(0,\sigma_h^2)$ avec $\sigma_1^2=\sigma^2$ et $\sigma_h^2=\sigma^2(1+(1+\theta_1)^2)$.
De plus, $\Cov(\widehat \varepsilon_{T+1\vert T},\widehat \varepsilon_{T+2\vert T})=\sigma^2(1+\theta_1)$. Donc :
$$
\begin{pmatrix}
	\widehat \varepsilon_{T+1\vert T} \\ \widehat \varepsilon_{T+2\vert T}
\end{pmatrix} \sim
\mathcal N \left(
\begin{pmatrix}
	0 \\ 0
\end{pmatrix}\right.,
\underbrace{
\sigma^2 
\begin{pmatrix}
	1 & 1+\theta_1\\ 1+\theta_1 & 1+ (1+\theta_1)^2
\end{pmatrix}}_{\Sigma}\left.\mathclap{\phantom{\begin{pmatrix} 0\\0 \end{pmatrix}}}
\right)
$$
D'où :
$$
\begin{pmatrix}
	\widehat \varepsilon_{T+1\vert T} & \widehat \varepsilon_{T+2\vert T}
\end{pmatrix}
\Sigma^{-1}
\begin{pmatrix}
	\widehat \varepsilon_{T+1\vert T} \\ \widehat \varepsilon_{T+2\vert T}
\end{pmatrix}\sim{\chi}^2(2) 
\quad\text{avec}\quad
\Sigma^{-1} = 
\frac{1}{\sigma^2}
\begin{pmatrix}
	 1+(1+\theta_1)^2 & - (1+\theta_1) \\ -(1+\theta_1) &1
\end{pmatrix}
$$
En notant $q_{1- \alpha}$ le quantile $1- \alpha$ d'une loi ${\chi}^2(2)$, une région de confiance de niveau $\alpha$ pour $(X_{T+1},X_{T+2})$ est :
\begin{equation}
R_\alpha=\left\{ 
\begin{pmatrix}
	x \\ y
\end{pmatrix}\: :\:
(1+(1+\theta_1)^2)(x-\widehat X_{T+1\vert T})^2-2(1+\theta_1)(x-\widehat X_{T+1\vert T})(y-\widehat X_{T+2\vert T}) + (y-\widehat X_{T+2\vert T})^2\leq \sigma^2q_{1-\alpha} 
\right\}
(\#eq:icCourtTerme)
\end{equation}

<!-- Si $\theta_1$ est connu on peut estimer $\sigma_h$ par $\widetilde \sigma_h$ avec : -->
<!-- $$ -->
<!-- \widetilde\sigma_1 = \widetilde\sigma=  \frac{1}{T-2}\sum_{t=2}^T\widehat\varepsilon_t^2 -->
<!-- \text{ et }\quad -->
<!-- \widetilde\sigma_2=\widehat\sigma\sqrt{1+(1+ \theta_1)^2} -->
<!-- $$ -->

<!-- L'intervalle de confiance \@ref(eq:icCourtTerme) reste valide en remplaçant $\sigma_h$ par $\widetilde \sigma_h$ et $q_{1-\frac \alpha 2}$ par le quantile $1-\frac \alpha 2$ d'une loi de Student de degré $T-2$.  -->

Le problème est que $\sigma_h$ et $\theta_1$ sont ici inconnus.
On estime donc $\theta_1$ par $\widehat \theta_1$, qui est l'estimation que l'on fait à partir de nos données et $\sigma$ par $\widehat \sigma= \frac{1}{T-2}\sum_{t=2}^T\widehat\varepsilon_t^2$.
En remplaçant $\sigma_h$ et $\theta_1$ par leurs valeurs estimées, la région de confiance définis dans l'équation \@ref(eq:icCourtTerme) reste valide mais **asymptotiquement uniquement**. 

[*Question 6*] En somme, la région de confiance pour $(X_{T+1},X_{T+2})$ est une ellipse, dont le centre est $(X_T + \widehat\theta_1\varepsilon_T, X_T + \widehat\theta_1\varepsilon_T)$ et caractérisé par l'équation :

\begin{equation}
\begin{split}
R_{1-\alpha}=\left\{ 
\begin{pmatrix}
	x \\ y
\end{pmatrix}\: :\:\right.
&(1+(1+\widehat\theta_1)^2)( X_T + \widehat\theta_1\varepsilon_T-x)^2
-
2(1+\widehat\theta_1)(X_T + \widehat\theta_1\varepsilon_T-x)(X_T + \widehat\theta_1\varepsilon_T-y) \\
&+
(X_T + \widehat\theta_1\varepsilon_T-y)^2\leq \widehat\sigma^2q_{1-\alpha} 
\left.\right\}
\end{split}
(\#eq:icPrev)
\end{equation}

L'application numérique ($\alpha = 0,05$, $\widehat\theta_1\simeq -0,38$, $X_T\simeq102,66$, $\varepsilon_T\simeq-2,63$, $\hat \sigma^2 \simeq 14,73$, $q_{0,95} \simeq 5,99$) donne :
\begin{equation}
R_{95\%}=\left\{ 
\begin{pmatrix}
	x \\ y
\end{pmatrix}\: :\:
0,016 x^2 - 0,014 \times x \times y + 0,011 y^2 - 1,798 x - 0,885 y + 139,044 = 1
\right\}
(\#eq:icApplique)
\end{equation}

<!-- \begin{equation} -->
<!-- IC_{1-\alpha}\begin{pmatrix} X_{T+1} -->
<!-- \\ X_{T+2}\end{pmatrix} = -->
<!-- \left[ -->
<!--   \begin{pmatrix}  -->
<!--     X_T + \widehat\theta_1\varepsilon_T  -->
<!--     \\ X_T + \widehat\theta_1\varepsilon_T  -->
<!--   \end{pmatrix} -->
<!--   - -->
<!--   \widehat\sigma q_{1-\frac \alpha 2} -->
<!--   \begin{pmatrix}  -->
<!--     1\\ -->
<!--     \sqrt{1+(1+\widehat \theta_1)^2} -->
<!--   \end{pmatrix} -->
<!--   \;;\; -->
<!--   \begin{pmatrix}  -->
<!--     X_T - \widehat\theta_1\varepsilon_T  -->
<!--     \\ X_T - \widehat\theta_1\varepsilon_T  -->
<!--   \end{pmatrix} -->
<!--   + -->
<!--   \widehat\sigma q_{1-\frac \alpha 2} -->
<!--   \begin{pmatrix}  -->
<!--     1\\ -->
<!--     \sqrt{1+(1+\widehat \theta_1)^2} -->
<!--   \end{pmatrix} -->
<!-- \right] -->
<!-- (\#eq:icPrev) -->
<!-- \end{equation} -->

[*Question 7*] Pour obtenir cette région de confiance il faut :

- que le modèle suivit par notre série entre janvier 2010 et février 2020 soit bien un modèle ARIMA(0,1,1). Le modèle doit être en théorie parfaitement identifié ($\sigma$ et $\theta_1$ connus ou a minima que leurs estimateurs convergent vers leurs valeurs) ;
- que les résidus de notre modèle ARIMA soient **indépendants, homoscédastiques et suivent une loi normale** : ce qui a bien été vérifié dans la partie précédente ;
- que $T$ soit grand (dans notre cas $T=120$).  


[*Question 8*] Le graphique \@ref(fig:RegIC) présente la région de confiance au seuil 95 \%, les intervalles de confiance associés aux deux prévision (lorsqu'on les calcule de manière indépendante pour $X_{T+1}$ et $X_{T+2}$), ainsi que les dernières valeurs publiées de l'IPI automobile de janvier et de février 2020. 
On retrouve ce que l'on a montré par l'équation \@ref(eq:icPrev) : la même valeur est prédite pour $X_{T+1}$ et $X_{T+2}$. 
Prédire les mêmes valeurs pour les deux dates paraît économiquement peu cohérent, mais cela reflète la dynamique du modèle ARIMA(0,1,1) :

- Puisqu'il y a aucun ordre autorégressif, $\Delta X_t$ ne dépend pas des valeurs passées prises par $(\Delta X_{t'})_{t'\leq t-1}$.

- Puisque l'ordre MA est égal à 1, il n'y a aucune influence du bruit à l'horizon supérieur ou égal à 2 : sans aucune information supplémentaire, la seule prévision possible pour $\Delta X_{t+h}$, $h\geq 2$, est une prévision nulle, et donc pour $X_{t+h}$ la seule prévision possible est $\widehat X_{t+1\vert t}$. 
Cette incertitude se traduit par une région de confiance très large^[On prévoit une évolution mensuelle entre décembre 2019 et janvier 2020 comprise entre -6,8 \% et +8,7 \%, ce qui est très grand compte tenu de la volatilité de la série (l'écart-type de la série en évolution est de 4,1 et sa moyenne de 0,1).
].

La forme allongée et orientée à 45 degrés de la région de confiance reflète une certaine cohérence entre les prévisions de $X_{T+1}$ et $X_{T+2}$ (que l'on a pas quand on construit des intervalles de confiance de manière indépendante). 
En effet, plus  $\widehat X_{T+1\vert T}$ est grand, plus les valeurs « plausibles » de $\widehat X_{T+2\vert T}$ sont élevées.
<!-- Par ailleurs, le grand axe de l'ellipse (au plus long diamètre) n'est pas sur la première bissectrice : cela reflète que l'on ne peut avoir de « trop » grandes (ou « trop » petites) valeurs à la fois pour $\widehat X_{T+1\vert T}$ et $\widehat X_{T+2\vert T}$. -->
<!-- Plus précisément, au seuil $\alpha$, si $\widehat X_{T+1\vert T}$ atteint sa plus grande valeur possible (le point le plus à droite de l'ellipse), alors $\widehat X_{T+2\vert T}<\widehat X_{T+1\vert T}$. -->
Toutefois, le grand axe de l'ellipse n'est pas aligné à la première bissectrice : si $\widehat X_{T+1\vert T}$ atteint sa plus grande valeur possible alors  $\widehat X_{T+2\vert T}<\widehat X_{T+1\vert T}$ (il y a dans ce cas un contrecoup économique). 


\begin{figure}[htbp]
\begin{center}\includegraphics[width = 0.8\textwidth]{img/ellipse} \end{center}
\captionsetup{margin=0cm,format=hang,justification=justified}
\caption{Région de confiance pour la prévision de l'IPI automobile CVS-CJO pour janvier et février 2020 par un modèle ARIMA(0,1,1)}\label{fig:RegIC}
\end{figure}

```{r prevIpi, fig.cap= "Prévisions de l'IPI automobile CVS-CJO pour janvier et février 2020 par un modèle ARIMA(0,1,1).", fig.height=3}
ordres_retenus <- readRDS(file = "../data/ordres_retenus.RDS")
model_estime <- Arima(x, order = ordres_retenus, include.constant = FALSE)
prev <- forecast(model_estime, h = 2)

graph_prev(x, x_complet, prev, n_xlabel = 12)
```


## Question 9 : question ouverte sur la causalité


Soit $Y_t$ une série stationnaire disponible de $t = 1$ à $T$ telle que $Y_{T+1}$ est disponible plus rapidement que $X_{T+1}$. 

$Y_t$ cause^[
Cette notion de causalité n'est pas la même que celle utilisée en économétrie classique (une influence directe de $Y_t$ sur $X_t$), cela signifie simplement ici que $Y_t$ est utile pour prévoir $X_t$.
] instantanément $X_t$ au sens de Granger ($C_{X - Y}$^[
La relation de causalité instantanée de Granger est symétrique : $C_{X - Y} \iff C_{Y - X}$.
]) si et seulement si pour tout $t$, la valeur de $Y_{t+1}$ permet d'améliorer la prévision de $X_{t+1}$. 
Ainsi, la causalité instantanée au sens de Granger est une condition suffisante pour que $Y_{T+1}$ permette d'améliorer la prévision de $X_{T+1}$. 
Mathématiquement : 

$$ \underbrace{\forall t \quad \widehat X_{t+1 \vert \{Y_u, X_u, u \le t \}  \cup \{Y_{t+1}\}}   \ne \widehat X_{t+1 \vert \{Y_u, X_u, u \le t \}}}_{C_{X - Y} \text{ }:\text{ } Y_t \textrm{ cause instantanément au sens de Granger } X_t} \overset{\text{en particulier}}{\Longrightarrow} \widehat X_{T+1 \vert \{Y_{1 \dots T},X_{1 \dots T}\} \cup \{Y_{T+1}\}} \ne \widehat X_{T+1 \vert \{Y_{1 \dots T},X_{1 \dots T}\}}$$


<!-- c'est-à-dire que la prédiction de $X_t$ à la date $T+1$ ($X_{t+1}$) sachant toutes les valeurs passées de $X_t$ et $Y_t$ ainsi que la valeur $Y_{T+1}$ est différente de celle où on ne connaîtrait pas la valeur de $Y_{T+1}$   -->

<!-- l’erreur quadratique moyenne de prédiction de $X_{T+1}$ est inférieure à celle calculée sans utiliser $Y_t$. -->

Cette définition de causalité instantanée est fondée sur les corrélations entre les erreurs. 
En effet, si $(Y_t',X_t')'$ est bien **stationnaire** alors on a montré dans le cours que : 

$$C_{X - Y} \iff Cov(\epsilon_{1t},\epsilon_{2t}) = 0 \quad \text{avec} \quad \begin{pmatrix} \epsilon_{1t}
\\\epsilon_{2t}\end{pmatrix} = \begin{pmatrix} Y_t - \widehat Y_{t \vert \{Y_u, X_u, u \le t-1 \}}
\\\ X_t - \widehat X_{t \vert \{Y_u, X_u, u \le t-1 \}}\end{pmatrix}$$
 

En prenant bien le soin de choisir $X_t$ et $Y_t$ de manière à ce que $(Y_t',X_t')'$ soit stationnaire, vérifier que $Y_{T+1}$ permet d'améliorer la prévision de $X_{T+1}$ revient alors à tester la condition suivante après avoir estimé les modèles correspondants à l'évolution de $X_t$ et $Y_t$ : 
 
$$Cov( Y_{T+1} - \widehat Y_{T+1 \vert \{Y_{1 \dots T},X_{1 \dots T} \} }, X_{T+1} - \widehat X_{T+1 \vert \{Y_{1 \dots T},X_{1 \dots T} \} }) = 0$$
En notant $X_t$ notre série de l'IPI de l'industrie automobile stationnarisée, il faudrait par exemple prendre pour $Y_t$ des données susceptibles d'être disponibles avant $X_t$ et feraient de bons candidats pour prévoir l'évolution de l'IPI dans l'industrie automobile :

- un IPI correspondant à une composante de la division « industrie automobile » (29)^[
Par exemple une des classes parmi la construction de véhicules automobiles (29.1), la fabrication de carrosseries et remorques (29.2) ou les équipements automobiles (29.3).
] qu'il faudrait différencier autant de fois que nécessaire pour qu'elle soit bien stationnaire. 
Certaines composantes peuvent en effet disponibles être avant leur agrégat.

- une série stationnaire issue d'une autre enquête qui donnerait de l'information sur la production de l'IPI de l'industrie automobile. 
Cela peut par exemple être le cas des résultats des enquêtes de conjoncture, de l'Insee ou de la Banque de France, auprès des entreprises de ce secteur. 
Dans ces enquêtes on demande en effet l'opinion des chefs d'entreprise sur l'évolution passée et future de leur production : ces informations sont qualitatives et sont donc connues bien avant les informations quantitatives demandées par l'enquête mensuelle de branche. 

Il peut également exister des cas où  $Y_{T+1}$ permet d'améliorer la prévision de $X_{T+1}$ mais sans que $Y_t$ cause instantanément $X_t$.  
Prenons, par exemple, pour $X_T$ la série stationnarisée de l'indice de production industrielle dans la cokéfaction-raffinage. 
Cette série est très bruitée car en France la production de ce poste est concentrée en une dizaine de raffineries. 
Ainsi, il est très difficile d'avoir une prévision précise de cette série qui sera très sensible, par exemple, à l'arrêt d'une raffinerie pendant quelques jours.
En revanche, si on dispose d'un indicateur $Y_t$ du nombre de jours de fermeture dans le mois, cette série peut, dans certains cas, permettre d'améliorer de manière conséquente la prévision de $X_t$. 
C'est par exemple le cas pendant les périodes de grèves : l'analyse de l'évolution de la production pendant les grèves passées permet d'estimer l'effet moyen d'un jour de grève, et cela permet donc d'estimer l'évolution future de la production pendant les mouvements sociaux futurs.  
Si en $T+1$ il y a des grèves dans les raffineries, $Y_{T+1}$ est connu bien avant $X_{T+1}$ et permet d'améliorer la prévision de $X_{T+1}$.  
Puisque les fermetures de raffineries sont rares (elles sont ouvertes tous les jours de la semaine), pour la majorité des périodes $t$, $Y_t$ ne permet pas d'améliorer la prévision de $X_t$ : elle ne cause donc a priori pas instantanément $X_t$ au sens de Granger.

\newpage


# (APPENDIX) Appendix {-}

\setcounter{page}{0}
\pagenumbering{roman}

# Tests supplémentaires sur la qualité des modèles {#sec:qualRes}


```{r tablbtest}
format_testlb(models_evalues, 
            var = "lbtest",
            titre = "Tests de Ljung-Box sur les résidus (tests d'autocorrélation) des modèles ARIMA sur l'IPI de l'automobile.")
```

\

```{r tabcoefs}
format_tab_coef(models_evalues, 
            titre = "Estimation des coefficients associés aux modèles ARIMA sur l'IPI de l'automobile.")
```

\
```{r tablb2test}
format_testlb(models_evalues, 
            var = "lb2test",
            titre = "Tests de Ljung-Box sur le carré des résidus (tests d'homoscédasticité) des modèles ARIMA sur l'IPI de l'automobile.") #%>% 
		#footnote(footnote_order= c("general","symbol"), #marche pas
		#		 symbol = "",
		#		 symbol_manual = c(''))
```


```{r tabjb}
format_jbtest(models_evalues, 
            titre = "Tests de Jarque-Bera de normalité des résidus des modèles ARIMA sur l'IPI de l'automobile.") #%>% 
		# footnote(footnote_order= c("symbol","general"), #marche pas
		# 		 symbol = "\n\nL’hypothèse (H0) de normalité des résidus n’est pas rejetée à 5 % pour l’ensemble des modèles\net en particulier pour le modèle retenu ARIMA(0,1,1).",
		# 		 symbol_manual = c(''))
```

\newpage 
\ 
\newpage

# Code \faRProject{}

L'ensemble du code a été écrit avec l'encodage UTF-8.

## Fichier `0 - Creation des donnees.R`

Code utilisé pour télécharger les données : non utile pour la suite puisque les données sont jointes au projet.

```{r, eval=FALSE, echo = TRUE}
# Codes pour télécharger les séries : 
# il n'est pas nécessaire de le relancer puisqu'elles
# sont toutes dans le dossier data/

# devtools::install_github("aqlt/AQLTools")
 library(AQLTools)
 library(zoo)
 
# CL1 = automobile

ipi_cl1 <- AQLTools::lectureBDM("010537940")
ipi_cl1_brut <- AQLTools::lectureBDM("010537939")
data_b <- ts.union(ipi_cl1, ipi_cl1_brut)
data_2010 <- window(data_b,
				  start = c(2010, 1),
				  end = c(2019,12))

saveRDS(data_b,
		file = "data/donnees_completes.RDS")
saveRDS(data_2010,
		file = "data/donnees.RDS")

# Exporter en CSV : non utile pour lancer les programmes mais demandé par les consignes
write.csv(data.frame(date = format(as.yearmon(time(data_2010)), "%m/%Y"),
							  data_2010),
				   row.names = FALSE,
				   file = "data/donnees.csv")

# Pour tracer le graphique avec ggplot2
AQLTools::graph_ts(window(data,start = 2005))
```

## Fichier `1 - Stationnarisation.R`


```{r, eval=FALSE, echo = TRUE}
library(urca)
library(fUnitRoots)
# devtools::install_github("aqlt/AQLTools")
library(AQLTools) # utiliser pour tracer les séries
library(patchwork)

data <- readRDS(file = "data/donnees.RDS")
# data <- ts(read.csv("data/donnees.csv")[,-1],
# 		   start = 2010, frequency = 12)


x <- data[,"ipi_cl1"]
p1 <- AQLTools::graph_ts(window(x,
								start = c(2009,10),
								end = c(2020,2),
								extend = TRUE), x_lab = "Dates", y_lab = NULL,
						 titre = "IPI-CL1 (sans traitement)", n_xlabel = 6)
p1
t1 <- time(x)*(time(x)<2013)
t2 <- time(x)*(time(x)>=2013)
summary(lm(x ~ time(x)+t2))

# Il y a une tendance assez nette et pas de moyenne : 
# on peut faire le test ADF avec constante et tendance
# Pour que le test soit valide il faut rajouter des retards :
# On fait donc le test jusqu'à ce que les résidus du modèles de "ADF" soient bons :
# que les résidus soient indépendants (on ne veut plus d'endogénéité dû aux variables omises)
lb_test <- function(x, lag_max = 24, fitdf = 0){
	t(sapply(seq_len(lag_max),function(l){
		if(l <= fitdf){
			b <- list(statistic = NA, p.value = NA)
		}else{
			b <- Box.test(x,"Ljung-Box",lag = l,
						  fitdf = fitdf
			)
		}
		data.frame(lag = l,
				   b$statistic,
				   b$p.value
		)
	}))
}# ces deux fonctions sont équivalentes : en haut la fonction AQLT, en bas TD
Qtests <- function(series, k = 24, fitdf=0) {
	pvals <- apply(matrix(1:k), 1, FUN=function(l) {
		pval <- if (l<=fitdf) NA else Box.test(series, lag=l, type="Ljung-Box", fitdf=fitdf)$p.value 
		return(c("lag"=l,"pval"=pval))
	})
	return(t(pvals))
}
adfTest_valid <- function(series, kmax,type){ 
	k <- 0
	noautocorr <- 0
	while (noautocorr==0){
		cat(paste0("ADF with ",k, " lags: residuals OK? "))
		adf <- adfTest(series,lags=k,type=type)
		pvals <- Qtests(adf@test$lm$residuals,24,fitdf=length(adf@test$lm$coefficients))[,2] 
		if (sum(pvals<0.05,na.rm=T) == 0) {
			noautocorr <- 1; cat("OK \n")
		} else cat("nope \n")
		k <- k + 1
	}
	return(adf)
}

# On trouve un lag de trois :
adfTest_valid(x, kmax = 20, type = "ct")
adfTest_valid(x, kmax = 20, type = "c")#juste constante

adf <- adfTest(x, type = "ct",lags = 2) #constante et tendance 
adf
adf <- adfTest(x, type = "c",lags = 2)#juste constante
adf # on ne rejette pas : série non stationnaire.
# A priori c'est donc plutôt une marchine aléatoire qu'une tendance déterministe.
# vérification tests indépendance
lb_test(adf@test$lm$residuals, fitdf=length(adf@test$lm$coefficients)) 


# PP et kpss donnent des résultats similaires
PP.test(x) 
tseries::kpss.test(x)


# On différentie la série pour la stationnariser :
x_st <- diff(x, 1)
AQLTools::graph_ts(window(x_st,
						  start = c(2009,10),
						  end = c(2020,2),
						  extend = TRUE), x_lab = "Dates", y_lab = NULL,
				   titre = "IPI-CL1 différenciée", n_xlabel = 12)
summary(lm(x_st ~ time(x_st)))

# Série qui parait stationnaire 
adfTest_valid(x_st, kmax = 24, type = "nc") # lag2

adf <- adfTest(x_st, type = "nc",lags = 1)
adf # on rejette : série stationnaire.
PP.test(x_st) # vérifié avec test de Phillips-Perron
tseries::kpss.test(x_st) # vérifié avec KPSS

series_a_tracer <- ts.union(x, x_st)
p2 <- AQLTools::graph_ts(window(x_st,
								start = c(2009,10),
								end = c(2020,2),
								extend = TRUE), x_lab = "Dates", y_lab = NULL,
						 titre = "IPI-CL1 (série différenciée)", n_xlabel = 6)
p1 + p2 # pas de tendance et a-priori séries stationnaire

saveRDS(x_st, file = "data/x_st.RDS")
```

## Fichier `2 - Estimation du modele ARIMA.R`

```{r, eval=FALSE, echo = TRUE}
library(forecast)
library(patchwork)

data <- readRDS(file = "data/donnees.RDS")
# data <- ts(read.csv("data/donnees.csv")[,-1],
# 		   start = 2010, frequency = 12)

x <- data[,"ipi_cl1"]
x_st <- readRDS(file = "data/x_st.RDS")
acf(x_st) # q_max = 1
pacf(x_st) # p_max = 1

# Fonctions identiques du package forecast mais où on enlève lag = 0
# Permet d'éviter les confusions pour l'acf
Acf(x_st)
Pacf(x_st)

ggAcf(x_st) + labs(title = "ACF") +
	ggPacf(x_st) + labs(title = "PACF")

# On va tester tous les modèles pour q <= 1, p <= 1

evaluation_model <- function(order, x, lags = 24, include.mean = TRUE){
	# ici on utilise Arima plutôt que arima pour la fonction accuracy
	model <- forecast::Arima(x, order = order,
							 include.mean = include.mean)
	residus <- residuals(model)
	lbtest <- t(sapply(1:lags,function(l){
		if(l <= sum(model$arma[1:2])){
			b <- list(statistic = NA, p.value = NA)
		}else{
			b <- Box.test(residus,"Ljung-Box",lag = l,
						  fitdf = sum(model$arma[1:2])
			)
		}
		data.frame(lag = l,
				   b$statistic,
				   b$p.value
		)
	}))
	lb2test <- t(sapply(1:lags,function(l){
		if(l <= sum(model$arma[1:2])){
			b <- list(statistic = NA, p.value = NA)
		}else{
			b <- Box.test(residus^2,"Ljung-Box",lag = l,
						  fitdf = sum(model$arma[1:2])
			)
		}
		data.frame(lag = l,
				   b$statistic,
				   b$p.value
		)
	}))
	jbtest <- tseries::jarque.bera.test(residus)
	ttest <- tryCatch(lmtest::coeftest(model), error = function(e) 0)
	qualite <- c(AIC(model), BIC(model), accuracy(model))
	names(qualite) <- c("AIC", "BIC", colnames(accuracy(model)))
	list(model = model,
		 ttest = ttest,
		 lbtest = lbtest, lb2test = lb2test,
		 jbtest = jbtest,
		 qualite = qualite)
	
}

models_possibles <- expand.grid(p = 0:1, d = 0, q = 0:1)
models_evalues <- apply(models_possibles,1, evaluation_model, x = x_st,
						include.mean = FALSE)
names(models_evalues) <- sprintf("ARIMA(%i,%i,%i)", models_possibles[,"p"],
								 models_possibles[,"d"], models_possibles[,"q"])
saveRDS(models_evalues, file = "data/models_evalues.RDS")
## Pour éviter de tout écrire à la main :
#cat(paste(sprintf("models_evalues$`%s`",names(models_evalues)),collapse = "\n"))

models_evalues$`ARIMA(0,0,0)`
# Il n'y a pas indépendance des résidus
models_evalues$`ARIMA(1,0,0)`
# Il n'y a pas indépendance des résidus
models_evalues$`ARIMA(0,0,1)`
# Modele bon
models_evalues$`ARIMA(1,0,1)`
# coef AR1 non significatif

# Bilan : seul modèle valide : ARIMA(0,1,1)

qualite_modeles <- sapply(models_evalues, function(x) x$qualite)
round(qualite_modeles,1)

ordres_retenus <- c(0,1,1)
saveRDS(ordres_retenus, file = "data/ordres_retenus.RDS")

model_estime <- arima(x, order = ordres_retenus)
model_estime
lmtest::coeftest(model_estime) # coefficients significatifs
residus <- residuals(model_estime)
lbtest <- t(sapply(1:24,function(l){
	if(l <= sum(model_estime$arma[1:2])){
		b <- list(statistic = NA, p.value = NA)
	}else{
		b <- Box.test(residus,"Ljung-Box",lag = l,
					  fitdf = sum(model_estime$arma[1:2])
		)
	}
	data.frame(lag = l,
			   b$statistic,
			   b$p.value
	)
}))
lbtest # résidus biens valides
# On remarque que rien ne reste dans ACF/PACF
ggAcf(residus) + labs(title = "ACF") + 
	ggPacf(residus) + labs(title = "PACF")
#Modèle bien valide

tseries::jarque.bera.test(residus) # résidus normaux : on peut bien faire les ic

#Remarquons que le modèle que le même modèle serait determiné automatiquement
m <- auto.arima(x)
m
```

## Fichier `3 - Previsions.R`

```{r, eval=FALSE, echo = TRUE}
library(forecast)
library(patchwork)
library(conics)

data <- readRDS(file = "data/donnees.RDS")
# data <- ts(read.csv("data/donnees.csv")[,-1],
# 		   start = 2010, frequency = 12)

data_complet <- readRDS(file = "data/donnees_completes.RDS")
x <- data[, "ipi_cl1"]
x_complet <- data_complet[, "ipi_cl1"]
ordres_retenus <- readRDS(file = "data/ordres_retenus.RDS")
model_estime <- Arima(x, order = ordres_retenus, include.constant = FALSE)
prev <- forecast(model_estime, h = 2)
prev
plot(prev)

#Retrouver les IC : 
res <- residuals(model_estime)
sum((res - mean(res))^2) / (length(res) - 2) # sigma2
prev$mean[1]+sqrt(model_estime$sigma2)*qnorm(1-0.05/2)
prev$mean[2]+sqrt(model_estime$sigma2*(1+(1+model_estime$coef[1])^2))*qnorm(1-0.05/2)

# Plutôt que de tracer les IC on veut une région de confiance :
sigma2 <- model_estime$sigma2
theta <- coef(model_estime)

# matlib::Inverse(matrix(c(1, (1+theta),
# 				 (1+theta),1+(1+theta)^2),ncol = 2))
sigma_m1 = matrix(c(1+(1+theta)^2, -(1+theta),
					-(1+theta),1),ncol = 2)
alpha = 0.05
sigma_m1 <- sigma_m1/(sigma2*qchisq(1-alpha, 2))
prevs <- prev$mean

a = sigma_m1[1,1]
b = sigma_m1[1,2]
d = sigma_m1[2,2]
x_p = prevs[1]
y_p = prevs[2]
a_1 <- a
a_2 <- 2*b
a_3 <- d
a_4 <- -2*(a*x_p+b*y_p)
a_5 <- -2*(b*x_p+d*y_p)
a_6 <- a*x_p*x_p+2*b*x_p*y_p+d*y_p*y_p

ellispe_eq <- c(a_1, a_2, a_3, a_4,
				a_5, a_6)
# a_1 * x^2 + a_2 * x * y + a_3 * y^2 + a_4 * x + a_5 * y + a_6 = 1
eq <- paste(round(ellispe_eq, 3),c("x^2","* x * y","y^2","x","y",1),
			collapse = " + ")
eq <- paste(gsub("+ -","- ", eq,fixed = TRUE),"= 1")
eq <- gsub(" 1 ", " ", eq,fixed = TRUE)
eq
#equation latex :
cat(gsub(".", ",",
		 gsub("*","\\times", eq, fixed = TRUE),
		 fixed = TRUE))

# Pour tracer l'ellispe :
# equation sous la forme :
# a_1 * x^2 + a_2 * x * y + a_3 * y^2 + a_4 * x + a_5 * y + a_6 = 0
ellipse <- conicPlot(ellispe_eq - c(0,0,0,0,0,1))
ellipse
points(prevs[1], prevs[2])

# Pour obtenir les plus grandes prévisions possibles pour T+1
ell <- function(x = 103.6517, y = 103.6517, 
				ellispe_eq = c(0.0157341205774816, -0.0141250037159479, 0.0113328509767077, 
							   -1.79765568338535, -0.885257713887019, 139.044239392918)){
	sum(ellispe_eq *c(x^2, x * y, y^2, x, y, 1)) - 1
}

(c(uniroot(ell,interval = c(95,97))$root,
  uniroot(ell,interval = c(111,113))$root) /102.66 - 1)*100
```

